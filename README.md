 DescripciÃ³n del Proyecto

WineClassifierML es un modelo de clasificaciÃ³n basado en Machine Learning que predice la calidad del vino tinto usando datos quÃ­micos.

âœ… Objetivo: Predecir si un vino tendrÃ¡ baja, media o alta calidad con base en sus caracterÃ­sticas quÃ­micas.âœ… Dataset: Se utilizÃ³ el conjunto de datos "winequality-red.csv", que contiene informaciÃ³n sobre 1599 vinos tintos con 11 variables quÃ­micas, como acidez, alcohol y sulfatos.âœ… Modelos utilizados:

Random Forest Classifier ğŸŒ²

LightGBM Classifier âš¡
âœ… OptimizaciÃ³n: Se aplicÃ³ RandomizedSearchCV y SMOTE para mejorar la detecciÃ³n de vinos de baja calidad.âœ… EvaluaciÃ³n: Se utilizaron mÃ©tricas como Accuracy, F1-score y Matriz de ConfusiÃ³n para medir el desempeÃ±o.

ğŸ“Š Datos y AnÃ¡lisis Exploratorio

El dataset contiene 12 columnas:

CaracterÃ­sticas quÃ­micas: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, sulphates, alcohol, etc.

Variable objetivo: quality (de 3 a 8, donde 3 es de menor calidad y 8 es de mayor calidad).

Durante el anÃ¡lisis exploratorio (EDA), se descubrieron patrones interesantes:
ğŸ“Œ Los vinos con mayor contenido de alcohol tienden a tener mejor calidad.ğŸ“Œ La acidez volÃ¡til tiene una correlaciÃ³n negativa con la calidad (mÃ¡s acidez = menor calidad).ğŸ“Œ El dataset estaba desbalanceado, con muy pocos vinos de calidad baja (clase 3 y 4).

ğŸ› ï¸ ImplementaciÃ³n del Modelo

1ï¸âƒ£ Preprocesamiento de Datos

Se creÃ³ una nueva variable categÃ³rica quality_category, dividiendo los vinos en baja, media y alta calidad.

Se aplicÃ³ StandardScaler para normalizar los datos.

Se crearon nuevas caracterÃ­sticas como total_acidity = fixed_acidity + volatile_acidity.

2ï¸âƒ£ Entrenamiento de Modelos

Se probaron Random Forest y LightGBM.

Se aplicÃ³ GridSearchCV para encontrar los mejores hiperparÃ¡metros.

Se utilizÃ³ SMOTE para equilibrar las clases y mejorar la predicciÃ³n de vinos de baja calidad.

3ï¸âƒ£ EvaluaciÃ³n del Modelo

MÃ©trica

Random Forest

LightGBM

Accuracy

83%

87%

F1-score ponderado

0.83

0.87

Clase 0 (baja calidad) - Recall

0.15

0.15

ğŸ”¹ LightGBM tuvo el mejor desempeÃ±o en general, pero aÃºn hay dificultades para predecir vinos de baja calidad.

ğŸ’¡ Conclusiones y PrÃ³ximos Pasos

ğŸ”¹ LightGBM fue el modelo mÃ¡s preciso para predecir la calidad del vino.ğŸ”¹ El modelo tiene problemas con la clase 0 (baja calidad), por lo que se recomienda recolectar mÃ¡s datos.ğŸ”¹ Factores clave como el alcohol y los sulfatos influyen directamente en la calidad del vino.

ğŸ“Œ Futuras mejoras:

Obtener mÃ¡s datos de vinos de baja calidad para mejorar la predicciÃ³n de la clase 0.

Probar modelos como XGBoost o una combinaciÃ³n de modelos (VotingClassifier).

Explorar nuevas caracterÃ­sticas quÃ­micas para mejorar la predicciÃ³n.


ğŸ“¬ Contacto

ğŸ“Œ Desarrollado por: Diego De la Fuente PratsğŸ“Œ LinkedIn: https://www.linkedin.com/in/diegodelafuenteprats/ ğŸ“Œ GitHub: Delafupra ğŸ“Œ Email: diegodelaf18@gmail.com

Si te gustÃ³ este proyecto, Â¡no olvides darle â­ en GitHub! ğŸš€ğŸ·

